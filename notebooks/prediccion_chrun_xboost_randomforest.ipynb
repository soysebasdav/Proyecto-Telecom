{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braco\\AppData\\Local\\Temp\\ipykernel_36408\\804781050.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_without_churn['TotalCharges'].fillna(df_without_churn['TotalCharges'].mean(), inplace=True)\n",
      "c:\\Users\\braco\\OneDrive\\Documentos\\Proyectos_Programacion\\Python\\posibles_clientes\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:26:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación para XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85      1552\n",
      "           1       0.59      0.51      0.55       561\n",
      "\n",
      "    accuracy                           0.78      2113\n",
      "   macro avg       0.71      0.69      0.70      2113\n",
      "weighted avg       0.77      0.78      0.77      2113\n",
      "\n",
      "AUC-ROC para XGBoost: 0.8185\n",
      "Matriz de confusión para XGBoost:\n",
      "[[1355  197]\n",
      " [ 274  287]]\n",
      "\n",
      "Reporte de clasificación para Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87      1552\n",
      "           1       0.67      0.46      0.55       561\n",
      "\n",
      "    accuracy                           0.80      2113\n",
      "   macro avg       0.75      0.69      0.71      2113\n",
      "weighted avg       0.78      0.80      0.78      2113\n",
      "\n",
      "AUC-ROC para Random Forest: 0.8346\n",
      "Matriz de confusión para Random Forest:\n",
      "[[1426  126]\n",
      " [ 302  259]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv('../data/Telco-Customer-Churn.csv')\n",
    "\n",
    "# Eliminar la columna 'Churn' para no saber quién desertó\n",
    "df_without_churn = df.drop(columns=\"Churn\")\n",
    "\n",
    "# Limpiar valores nulos\n",
    "df_without_churn['TotalCharges'] = pd.to_numeric(df_without_churn['TotalCharges'], errors='coerce')\n",
    "df_without_churn['TotalCharges'].fillna(df_without_churn['TotalCharges'].mean(), inplace=True)\n",
    "\n",
    "# Codificación de variables categóricas\n",
    "label_encoder = LabelEncoder()\n",
    "binary_cols = [col for col in df_without_churn.select_dtypes(include='object').columns.tolist() if df_without_churn[col].nunique() == 2]\n",
    "\n",
    "for col in binary_cols:\n",
    "    df_without_churn[col] = label_encoder.fit_transform(df_without_churn[col])\n",
    "\n",
    "df_without_churn = pd.get_dummies(df_without_churn, drop_first=True)\n",
    "\n",
    "# Escalado de variables numéricas\n",
    "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "scaler = StandardScaler()\n",
    "df_without_churn[numeric_cols] = scaler.fit_transform(df_without_churn[numeric_cols])\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "X = df_without_churn\n",
    "y = df['Churn']  # La columna 'Churn' original será nuestra variable objetivo\n",
    "\n",
    "# Convertir 'Yes'/'No' a 1/0 en la columna 'Churn'\n",
    "y = y.map({'Yes': 1, 'No': 0})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "\n",
    "# ==========================================\n",
    "# Paso 3: Entrenar los modelos (XGBoost y Random Forest)\n",
    "# ==========================================\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# ==========================================\n",
    "# Paso 4: Realizar predicciones\n",
    "# ==========================================\n",
    "# Predicciones de probabilidad (predict_proba) para XGBoost\n",
    "y_prob_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Predicciones de probabilidad (predict_proba) para Random Forest\n",
    "y_prob_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Predicciones de clase\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# ==========================================\n",
    "# Paso 5: Guardar los modelos entrenados\n",
    "# ==========================================\n",
    "joblib.dump(xgb_model, '../modelos/xgboost_model.pkl')\n",
    "joblib.dump(rf_model, '../modelos/random_forest_model.pkl')\n",
    "\n",
    "# ==========================================\n",
    "# Paso 6: Guardar los resultados de las predicciones en un archivo CSV\n",
    "# ==========================================\n",
    "df_predicciones = pd.DataFrame({\n",
    "    'customerID': df.loc[X_test.index, 'customerID'],\n",
    "    'Probabilidad_Churn_XGBoost': y_prob_xgb,\n",
    "    'Probabilidad_Churn_RF': y_prob_rf,\n",
    "    'Riesgo_Churn_XGBoost': y_pred_xgb,\n",
    "    'Riesgo_Churn_RF': y_pred_rf\n",
    "})\n",
    "\n",
    "# Exportamos los resultados a un archivo CSV\n",
    "df_predicciones.to_csv('../report/predicciones_comparativas.csv', index=False)\n",
    "\n",
    "# ==========================================\n",
    "# Paso 7: Evaluación de los modelos\n",
    "# ==========================================\n",
    "# Evaluación de XGBoost\n",
    "print(\"Reporte de clasificación para XGBoost:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(f\"AUC-ROC para XGBoost: {roc_auc_score(y_test, y_prob_xgb):.4f}\")\n",
    "print(\"Matriz de confusión para XGBoost:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "\n",
    "# Evaluación de Random Forest\n",
    "print(\"\\nReporte de clasificación para Random Forest:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(f\"AUC-ROC para Random Forest: {roc_auc_score(y_test, y_prob_rf):.4f}\")\n",
    "print(\"Matriz de confusión para Random Forest:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
